{"pages":[{"title":"Probabilidad y Estadística con Python","text":"Actualmente con el boom de la Big Data , tener nociones de probabilidad y estadística se ha hecho fundamental. En los últimos años ha habido un resurgimiento de todo lo relacionado con estadística , data mining y machine learning empujados principalmente por la explosión de datos con que contamos, estos conceptos combinados forman la base de lo que actualmente se conoce como la Ciencia de Datos . Dentro de este contexto, Python es uno de los lenguajes que más nos facilita trabajar con datos. Realizar complejos análisis estadísticos nunca fue tan fácil como con Python ! ¿Qué es la Estadística? La estadística suele ser definida como la ciencia de aprender de los datos o como la ciencia de obtener conclusiones en la presencia de incertidumbre. Se relaciona principalmente con la recolección, análisis e interpretación de datos , así como también con la efectiva comunicación y presentación de los resultados basados en esos datos . Como por datos entendemos a cualquier clase de información grabada, la estadística juego un rol importante en muchas disciplinas científicas. La estadística puede ser muy importante para una efectiva toma de decisiones. Existe una gran cantidad de valiosa información escondida entre los datos , pero esta información no suele ser fácilmente accesible, la estadística nos brinda los principios fundamentales que nos permiten extraer y entender esa información; tambien nos proporciona las herramientas necesarias para verificar la calidad de nuestros datos y nuestra información. La estadística suele ser dividida en dos grandes ramas: La estadística descriptiva : La cual se dedica a recolectar, ordenar, analizar y representar a un conjunto de datos , con el fin de describir apropiadamente las características de este. Calcula los parámetros estadísticos que describen el conjunto estudiado. Algunas de las herramientas que utiliza son gráficos, medidas de frecuencias, medidas de centralización, medidas de posición, medidas de dispersión, entre otras. La estadistica inferencial : La cual estudia cómo sacar conclusiones generales para toda la población a partir del estudio de una muestra , y el grado de fiabilidad o significación de los resultados obtenidos. Sus principales herramientas son el muestreo , la estimación de parámetros y el contraste de hipótesis. ¿Qué es la Probabilidad? La probabilidad mide la mayor o menor posibilidad de que se dé un determinado resultado (suceso o evento) cuando se realiza un experimento aleatorio. Para calcular la probabilidad de un evento se toma en cuenta todos los casos posibles de ocurrencia del mismo; es decir, de cuántas formas puede ocurrir determinada situación.Los casos favorables de ocurrencia de un evento serán los que cumplan con la condición que estamos buscando. La probabilidad toma valores entre 0 y 1 (o expresados en tanto por ciento, entre 0% y 100%). La probabilidad es a la vez el inverso y complemento para la estadística . Dónde la estadística nos ayuda a ir desde los datos observados hasta hacer generalizaciones sobre como funcionan las cosas; la probabilidad funciona en la dirección inversa: si asumimos que sabemos como las cosas funcionan, entonces podemos averiguar la clase de datos que vamos a ver y cuan probable es que los veamos. La probabilidad también funciona como complemento de la estadística cuando nos proporciona una sólida base para la estadistica inferencial . Cuando hay incertidumbre, no sabemos que puede pasar y hay alguna posibilidad de errores, utilizando probabilidades podemos aprender formas de controlar la tasa de errores para reducirlos. Actividades básicas del analisis estadístico Las técnicas estadísticas deberían ser vistas como una parte importante de cualquier proceso de toma de dicisiones, permitiendo tomar decisiones estratégicamente informadas que combinen intuición con experiencia y un entendimiento estadístico de los datos que tenemos disponibles. Un análisis estadístico suele contener 5 actividades básicas: Diseño del análisis : Esta actividad involucra el planeamiento de los detalles para obtener los datos que necesitamos y la generación de la hipótesis a ser evaluada. Exploración de datos : En esta actividad nos dedicamos a jugar con nuestros datos, los describimos, los resumimos, realizamos gráficos para mirarlos desde distintos ángulos. Esta exploración nos ayuda a asegurarnos que los datos que obtuvimos son completos y que la etapa de diseño fue correcta. Armado del modelo : En esta actividad intentamos armar un modelo que explique el comportamiento de nuestros datos y pueda llegar a hacer predicciones sobre los mismos. La idea es que el modelo pueda describir las propiedades fundamentales de nuestros datos. Realizar estimaciones : Aquí vamos a intentar realizar estimaciones basadas en el modelo que armamos anteriormente. También vamos a intentar estimar el tamaño del error que nuestro modelo puede tener en sus predicciones. Contraste de la hipótesis : Esta actividad es la que va a producir la decisión final sobre si las predicciones del modelo son correctas y ayudarnos a concluir si los datos que poseemos confirman o rechazan la hipótesis que generamos en la actividad 1. Conceptos básicos de la estadística descriptiva En estadística descriptiva se utilizan distintas medidas para intentar describir las propiedades de nuestros datos, algunos de los conceptos básicos, son: Media aritmética : La media aritmética es el valor obtenido al sumar todos los datos y dividir el resultado entre el número total elementos. Se suele representar con la letra griega $\\mu$. Si tenemos una muestra de $n$ valores, $x_i$, la media aritmética , $\\mu$, es la suma de los valores divididos por el numero de elementos; en otras palabras: $$\\mu = \\frac{1}{n} \\sum_{i}x_i$$ Desviación respecto a la media : La desviación respecto a la media es la diferencia en valor absoluto entre cada valor de la variable estadística y la media aritmética. $$D_i = |x_i - \\mu|$$ Varianza : La varianza es la media aritmética del cuadrado de las desviaciones respecto a la media de una distribución estadística. La varianza intenta describir la dispersión de los datos . Se representa como $\\sigma&#94;2$. $$\\sigma&#94;2 = \\frac{\\sum\\limits_{i=1}&#94;n(x_i - \\mu)&#94;2}{n} $$ Desviación típica : La desviación típica es la raíz cuadrada de la varianza. Se representa con la letra griega $\\sigma$. $$\\sigma = \\sqrt{\\frac{\\sum\\limits_{i=1}&#94;n(x_i - \\mu)&#94;2}{n}} $$ Moda : La moda es el valor que tiene mayor frecuencia absoluta. Se representa con $M_0$ Mediana : La mediana es el valor que ocupa el lugar central de todos los datos cuando éstos están ordenados de menor a mayor. Se representa con $\\widetilde{x}$. Correlación : La correlación trata de establecer la relación o dependencia que existe entre las dos variables que intervienen en una distribución bidimensional. Es decir, determinar si los cambios en una de las variables influyen en los cambios de la otra. En caso de que suceda, diremos que las variables están correlacionadas o que hay correlación entre ellas. La correlación es positiva cuando los valores de las variables aumenta juntos; y es negativa cuando un valor de una variable se reduce cuando el valor de la otra variable aumenta. Covarianza : La covarianza es el equivalente de la varianza aplicado a una variable bidimensional. Es la media aritmética de los productos de las desviaciones de cada una de las variables respecto a sus medias respectivas.La covarianza indica el sentido de la correlación entre las variables; Si $\\sigma_{xy} > 0$ la correlación es directa; Si $\\sigma_{xy} < 0$ la correlación es inversa. $$\\sigma_{xy} = \\frac{\\sum\\limits_{i=1}&#94;n(x_i - \\mu_x)(y_i -\\mu_y)}{n}$$ Valor atípico : Un valor atípico es una observación que se aleja demasiado de la moda; esta muy lejos de la tendencia principal del resto de los datos . Pueden ser causados por errores en la recolección de datos o medidas inusuales. Generalmente se recomienda eliminarlos del conjunto de datos . Librerías de Python para probabilidad y estadística Como ya les vengo mostrando en mis anteriores artículos, Python se lleva muy bien con las matemáticas. Además, la comunidad python es tan amplia que solemos encontrar una librería para cualquier problema al que nos enfrentemos. En este caso, los principales módulos que Python nos ofrece para trabajar con probabilidad y estadística , son: numpy : El popular paquete matemático de Python , se utiliza tanto que mucha gente ya lo considera parte integral del lenguaje. Nos proporciona algunas funciones estadísticas que podemos aplicar fácilmente sobre los arrays de Numpy . scipy.stats : Este submodulo del paquete científico Scipy es el complemento perfecto para Numpy , las funciones estadisticas que no encontremos en uno, las podemos encontrar en el otro. statsmodels : Esta librería nos brinda un gran número de herramientas para explorar datos , estimar modelos estadísticos, realizar pruebas estadísticas y muchas cosas más. matplotlib : Es la librería más popular en Python para visualizaciones y gráficos. Ella nos va a permitir realizar los gráficos de las distintas distribuciones de datos. seaborn : Esta librería es un complemento ideal de matplotlib para realizar gráficos estadísticos. pandas : Esta es la librería más popular para análisis de datos y financieros. Posee algunas funciones muy útiles para realizar estadística descriptiva sobre nuestros datos y nos facilita sobremanera el trabajar con series de tiempo . pyMC : pyMC es un módulo de Python que implementa modelos estadísticos bayesianos, incluyendo la cadena de Markov Monte Carlo(MCMC) . pyMC ofrece funcionalidades para hacer el análisis bayesiano lo mas simple posible. Ejemplos en Python Calcular los principales indicadores de la estadística descriptiva con Python es muy fácil!. In [1]: # Ejemplos de estadistica descriptiva con python import numpy as np # importando numpy from scipy import stats # importando scipy.stats import pandas as pd # importando pandas np . random . seed ( 2131982 ) # para poder replicar el random In [2]: datos = np . random . randn ( 5 , 4 ) # datos normalmente distribuidos datos Out[2]: array([[ 0.46038022, -1.08942528, -0.62681496, -0.63329028], [-0.1074033 , -0.88138082, -0.34466623, -0.28320214], [ 0.94051171, 0.86693793, 1.20947882, -0.16894118], [-0.12790177, -0.58099931, -0.46188426, -0.18148302], [-0.76959435, -1.37414587, 1.37696874, -0.18040537]]) In [3]: # media arítmetica datos . mean () # Calcula la media aritmetica de Out[3]: -0.14786303590303568 In [4]: np . mean ( datos ) # Mismo resultado desde la funcion de numpy Out[4]: -0.14786303590303568 In [5]: datos . mean ( axis = 1 ) # media aritmetica de cada fila Out[5]: array([-0.47228757, -0.40416312, 0.71199682, -0.33806709, -0.23679421]) In [6]: datos . mean ( axis = 0 ) # media aritmetica de cada columna Out[6]: array([ 0.0791985 , -0.61180267, 0.23061642, -0.2894644 ]) In [7]: # mediana np . median ( datos ) Out[7]: -0.23234258265023794 In [8]: np . median ( datos , 0 ) # media aritmetica de cada columna Out[8]: array([-0.1074033 , -0.88138082, -0.34466623, -0.18148302]) In [9]: # Desviación típica np . std ( datos ) Out[9]: 0.73755354584071608 In [10]: np . std ( datos , 0 ) # Desviación típica de cada columna Out[10]: array([ 0.58057213, 0.78352862, 0.87384108, 0.17682485]) In [11]: # varianza np . var ( datos ) Out[11]: 0.54398523298221324 In [12]: np . var ( datos , 0 ) # varianza de cada columna Out[12]: array([ 0.337064 , 0.6139171 , 0.76359823, 0.03126703]) In [13]: # moda stats . mode ( datos ) # Calcula la moda de cada columna # el 2do array devuelve la frecuencia. Out[13]: (array([[-0.76959435, -1.37414587, -0.62681496, -0.63329028]]), array([[ 1., 1., 1., 1.]])) In [14]: datos2 = np . array ([ 1 , 2 , 3 , 6 , 6 , 1 , 2 , 4 , 2 , 2 , 6 , 6 , 8 , 10 , 6 ]) stats . mode ( datos2 ) # aqui la moda es el 6 porque aparece 5 veces en el vector. Out[14]: (array([6]), array([ 5.])) In [15]: # correlacion np . corrcoef ( datos ) # Crea matriz de correlación. Out[15]: array([[ 1. , 0.82333743, 0.15257202, 0.78798675, -0.02292073], [ 0.82333743, 1. , -0.13709662, 0.86873632, 0.41234875], [ 0.15257202, -0.13709662, 1. , -0.47691376, 0.21216856], [ 0.78798675, 0.86873632, -0.47691376, 1. , -0.03445705], [-0.02292073, 0.41234875, 0.21216856, -0.03445705, 1. ]]) In [16]: # calculando la correlación entre dos vectores. np . corrcoef ( datos [ 0 ], datos [ 1 ]) Out[16]: array([[ 1. , 0.82333743], [ 0.82333743, 1. ]]) In [17]: # covarianza np . cov ( datos ) # calcula matriz de covarianza Out[17]: array([[ 0.43350958, 0.18087281, 0.06082243, 0.11328658, -0.01782409], [ 0.18087281, 0.11132485, -0.0276957 , 0.06329134, 0.16249513], [ 0.06082243, -0.0276957 , 0.36658864, -0.06305065, 0.15172255], [ 0.11328658, 0.06329134, -0.06305065, 0.04767826, -0.00888624], [-0.01782409, 0.16249513, 0.15172255, -0.00888624, 1.39495179]]) In [18]: # covarianza de dos vectores np . cov ( datos [ 0 ], datos [ 1 ]) Out[18]: array([[ 0.43350958, 0.18087281], [ 0.18087281, 0.11132485]]) In [19]: # usando pandas dataframe = pd . DataFrame ( datos , index = [ 'a' , 'b' , 'c' , 'd' , 'e' ], columns = [ 'col1' , 'col2' , 'col3' , 'col4' ]) dataframe Out[19]: col1 col2 col3 col4 a 0.460380 -1.089425 -0.626815 -0.633290 b -0.107403 -0.881381 -0.344666 -0.283202 c 0.940512 0.866938 1.209479 -0.168941 d -0.127902 -0.580999 -0.461884 -0.181483 e -0.769594 -1.374146 1.376969 -0.180405 In [20]: # resumen estadistadistico con pandas dataframe . describe () Out[20]: col1 col2 col3 col4 count 5.000000 5.000000 5.000000 5.000000 mean 0.079199 -0.611803 0.230616 -0.289464 std 0.649099 0.876012 0.976984 0.197696 min -0.769594 -1.374146 -0.626815 -0.633290 25% -0.127902 -1.089425 -0.461884 -0.283202 50% -0.107403 -0.881381 -0.344666 -0.181483 75% 0.460380 -0.580999 1.209479 -0.180405 max 0.940512 0.866938 1.376969 -0.168941 In [21]: # sumando las columnas dataframe . sum () Out[21]: col1 0.395993 col2 -3.059013 col3 1.153082 col4 -1.447322 dtype: float64 In [22]: # sumando filas dataframe . sum ( axis = 1 ) Out[22]: a -1.889150 b -1.616652 c 2.847987 d -1.352268 e -0.947177 dtype: float64 In [23]: dataframe . cumsum () # acumulados Out[23]: col1 col2 col3 col4 a 0.460380 -1.089425 -0.626815 -0.633290 b 0.352977 -1.970806 -0.971481 -0.916492 c 1.293489 -1.103868 0.237998 -1.085434 d 1.165587 -1.684867 -0.223887 -1.266917 e 0.395993 -3.059013 1.153082 -1.447322 In [24]: # media aritmetica de cada columna con pandas dataframe . mean () Out[24]: col1 0.079199 col2 -0.611803 col3 0.230616 col4 -0.289464 dtype: float64 In [25]: # media aritmetica de cada fila con pandas dataframe . mean ( axis = 1 ) Out[25]: a -0.472288 b -0.404163 c 0.711997 d -0.338067 e -0.236794 dtype: float64 Histogramas y Distribuciones Muchas veces los indicadores de la estadística descriptiva no nos proporcionan una imagen clara de nuestros datos . Por esta razón, siempre es útil complementarlos con gráficos de las distribuciones de los datos , que describan con qué frecuencia aparece cada valor. La representación más común de una distribución es un histograma , que es un gráfico que muestra la frecuencia o probabilidad de cada valor. El histograma muestra las frecuencias como un gráfico de barras que indica cuan frecuente un determinado valor ocurre en el conjunto de datos . El eje horizontal representa los valores del conjunto de datos y el eje vertical representa la frecuencia con que esos valores ocurren. Las distribuciones se pueden clasificar en dos grandes grupos: Las distribuciones continuas , que son aquellas que presentan un número infinito de posibles soluciones. Dentro de este grupo vamos a encontrar a las distribuciones: normal , gamma , chi cuadrado , t de Student , pareto , entre otras Las distribuciones discretas , que son aquellas en las que la variable puede tomar un número determinado de valores. Los principales exponentes de este grupo son las distribuciones: poisson , binomial , hipergeométrica , bernoulli entre otras Veamos algunos ejemplos graficados con la ayuda de Python . Distribución normal La distribución normal es una de las principales distribuciones, ya que es la que con más frecuencia aparece aproximada en los fenómenos reales. Tiene una forma acampanada y es simétrica respecto de un determinado parámetro estadístico. Con la ayuda de Python la podemos graficar de la siguiente manera: In [26]: # Graficos embebidos. % matplotlib inline In [27]: import matplotlib.pyplot as plt # importando matplotlib import seaborn as sns # importando seaborn # parametros esteticos de seaborn sns . set_palette ( \"deep\" , desat =. 6 ) sns . set_context ( rc = { \"figure.figsize\" : ( 8 , 4 )}) In [28]: mu , sigma = 0 , 0.1 # media y desvio estandar s = np . random . normal ( mu , sigma , 1000 ) #creando muestra de datos In [29]: # histograma de distribución normal. cuenta , cajas , ignorar = plt . hist ( s , 30 , normed = True ) normal = plt . plot ( cajas , 1 / ( sigma * np . sqrt ( 2 * np . pi )) * np . exp ( - ( cajas - mu ) ** 2 / ( 2 * sigma ** 2 ) ), linewidth = 2 , color = 'r' ) Distribuciones simetricas y asimetricas Una distribución es simétrica cuando moda, mediana y media coinciden aproximadamente en sus valores. Si una distribución es simétrica, existe el mismo número de valores a la derecha que a la izquierda de la media, por tanto, el mismo número de desviaciones con signo positivo que con signo negativo. Una distribución tiene asimetria positiva (o a la derecha) si la \"cola\" a la derecha de la media es más larga que la de la izquierda, es decir, si hay valores más separados de la media a la derecha. De la misma forma una distribución tiene asimetria negativa (o a la izquierda) si la \"cola\" a la izquierda de la media es más larga que la de la derecha, es decir, si hay valores más separados de la media a la izquierda. Las distribuciones asimétricas suelen ser problemáticas, ya que la mayoría de los métodos estadísticos suelen estar desarrollados para distribuciones del tipo normal . Para salvar estos problemas se suelen realizar transformaciones a los datos para hacer a estas distribuciones más simétricas y acercarse a la distribución normal . In [30]: # Dibujando la distribucion Gamma x = stats . gamma ( 3 ) . rvs ( 5000 ) gamma = plt . hist ( x , 70 , histtype = \"stepfilled\" , alpha =. 7 ) En este ejemplo podemos ver que la distribución gamma que dibujamos tiene una asimetria positiva. In [31]: # Calculando la simetria con scipy stats . skew ( x ) Out[31]: 1.1437199125547868 Cuartiles y diagramas de cajas Los cuartiles son los tres valores de la variable estadística que dividen a un conjunto de datos ordenados en cuatro partes iguales. Q1, Q2 y Q3 determinan los valores correspondientes al 25%, al 50% y al 75% de los datos. Q2 coincide con la mediana . Los diagramas de cajas son una presentación visual que describe varias características importantes al mismo tiempo, tales como la dispersión y simetría. Para su realización se representan los tres cuartiles y los valores mínimo y máximo de los datos, sobre un rectángulo, alineado horizontal o verticalmente. Estos gráficos nos proporcionan abundante información y son sumamente útiles para encontrar valores atípicos y comparar dos conjunto de datos . In [32]: # Ejemplo de grafico de cajas en python datos_1 = np . random . normal ( 100 , 10 , 200 ) datos_2 = np . random . normal ( 80 , 30 , 200 ) datos_3 = np . random . normal ( 90 , 20 , 200 ) datos_4 = np . random . normal ( 70 , 25 , 200 ) datos_graf = [ datos_1 , datos_2 , datos_3 , datos_4 ] # Creando el objeto figura fig = plt . figure ( 1 , figsize = ( 9 , 6 )) # Creando el subgrafico ax = fig . add_subplot ( 111 ) # creando el grafico de cajas bp = ax . boxplot ( datos_graf ) # visualizar mas facile los atípicos for flier in bp [ 'fliers' ]: flier . set ( marker = 'o' , color = 'red' , alpha = 0.5 ) # los puntos aislados son valores atípicos In [33]: # usando seaborn sns . boxplot ( datos_graf , names = [ \"grupo1\" , \"grupo2\" , \"grupo3\" , \"grupo 4\" ], color = \"PaleGreen\" ); Regresiones Las regresiones es una de las herramientas principales de la estadistica inferencial . El objetivo del análisis de regresión es describir la relación entre un conjunto de variables, llamadas variables dependientes, y otro conjunto de variables, llamadas variables independientes o explicativas. Más específicamente, el análisis de regresión ayuda a entender cómo el valor típico de la variable dependiente cambia cuando cualquiera de las variables independientes es cambiada, mientras que se mantienen las otras variables independientes fijas. El producto final del análisis de regresión es la estimación de una función de las variables independientes llamada la función de regresión . La idea es que en base a esta función de regresión podamos hacer estimaciones sobre eventos futuros. La regresión lineal es una de las técnicas más simples y mayormente utilizadas en los análisis de regresiones . Hace suposiciones muy rígidas sobre la relación entre la variable dependiente $y$ y variable independiente $x$. Asume que la relación va a tomar la forma: $$ y = \\beta_0 + \\beta_1 * x$$ Uno de los métodos más populares para realizar regresiones lineales es el de mínimos cuadrados ordinarios (OLS, por sus siglas en inglés), este método es el estimador más simple y común en la que los dos $\\beta$s se eligen para minimizar el cuadrado de la distancia entre los valores estimados y los valores reales. Realizar análisis de regresiones en Python es sumamente fácil gracias a statsmodels . Veamos un pequeño ejemplo utilizando el dataset longley , el cual es ideal para realizar regresiones: In [34]: # importanto la api de statsmodels import statsmodels.formula.api as smf import statsmodels.api as sm # Creando un DataFrame de pandas. df = pd . read_csv ( 'https://vincentarelbundock.github.io/Rdatasets/csv/datasets/longley.csv' , index_col = 0 ) df . head () # longley dataset Out[34]: GNP.deflator GNP Unemployed Armed.Forces Population Year Employed 1947 83.0 234.289 235.6 159.0 107.608 1947 60.323 1948 88.5 259.426 232.5 145.6 108.632 1948 61.122 1949 88.2 258.054 368.2 161.6 109.773 1949 60.171 1950 89.5 284.599 335.1 165.0 110.929 1950 61.187 1951 96.2 328.975 209.9 309.9 112.075 1951 63.221 In [35]: # utilizando la api de formula de statsmodels est = smf . ols ( formula = 'Employed ~ GNP' , data = df ) . fit () est . summary () # Employed se estima en base a GNP. Out[35]: OLS Regression Results Dep. Variable: Employed R-squared: 0.967 Model: OLS Adj. R-squared: 0.965 Method: Least Squares F-statistic: 415.1 Date: Sat, 27 Jun 2015 Prob (F-statistic): 8.36e-12 Time: 15:30:24 Log-Likelihood: -14.904 No. Observations: 16 AIC: 33.81 Df Residuals: 14 BIC: 35.35 Df Model: 1 Covariance Type: nonrobust coef std err t P>|t| [95.0% Conf. Int.] Intercept 51.8436 0.681 76.087 0.000 50.382 53.305 GNP 0.0348 0.002 20.374 0.000 0.031 0.038 Omnibus: 1.925 Durbin-Watson: 1.619 Prob(Omnibus): 0.382 Jarque-Bera (JB): 1.215 Skew: 0.664 Prob(JB): 0.545 Kurtosis: 2.759 Cond. No. 1.66e+03 Como podemos ver, el resumen que nos brinda statsmodels sobre nuestro modelo de regresión contiene bastante información sobre como se ajuste el modelo a los datos. Pasemos a explicar algunos de estos valores: Dep. Variable: es la variable que estamos estimasdo. Model: es el modelo que estamos utilizando. R-squared: es el coeficiente de determinación , el cual mide cuan bien nuestra recta de regresion se aproxima a los datos reales. Adj. R-squared: es el coeficiente anterior ajustado según el número de observaciones. [95.0% Conf. Int.]: Los valores inferior y superior del intervalo de confianza del 95%. coef: el valor estimado del coeficiente. std err: el error estándar de la estimación del coeficiente. Skew: una medida de la asimetria de los datos sobre la media. Kurtosis: Una medida de la forma de la distribución. La curtosis compara la cantidad de datos cerca de la media con los que están más lejos de la media(en las colas). In [36]: # grafico de regresion. que tanto se ajusta el modelo a los datos. y = df . Employed # Respuesta X = df . GNP # Predictor X = sm . add_constant ( X ) # agrega constante X_1 = pd . DataFrame ({ 'GNP' : np . linspace ( X . GNP . min (), X . GNP . max (), 100 )}) X_1 = sm . add_constant ( X_1 ) y_reg = est . predict ( X_1 ) # estimacion plt . scatter ( X . GNP , y , alpha = 0.3 ) # grafica los puntos de datos plt . ylim ( 30 , 100 ) # limite de eje y plt . xlabel ( \"Producto bruto\" ) # leyenda eje x plt . ylabel ( \"Empleo\" ) # leyenda eje y plt . title ( \"Ajuste de regresion\" ) # titulo del grafico reg = plt . plot ( X_1 . GNP , y_reg , 'r' , alpha = 0.9 ) # linea de regresion In [37]: # grafico de influencia from statsmodels.graphics.regressionplots import influence_plot inf = influence_plot ( est ) Este último gráfico nos muestra el apalancamiento y la influencia de cada caso. La estadística bayesiana La estadística bayesiana es un subconjunto del campo de la estadística en la que la evidencia sobre el verdadero estado de las cosas se expresa en términos de grados de creencia. Esta filosofía de tratar a las creencias como probabilidad es algo natural para los seres humanos. Nosotros la utilizamos constantemente a medida que interactuamos con el mundo y sólo vemos verdades parciales; necesitando reunir pruebas para formar nuestras creencias. La diferencia fundamental entre la estadística clásica (frecuentista) y la bayesiana es el concepto de probabilidad . Para la estadística clásica es un concepto objetivo, que se encuentra en la naturaleza, mientras que para la estadística bayesiana se encuentra en el observador, siendo así un concepto subjetivo. De este modo, en estadística clásica solo se toma como fuente de información las muestras obtenidas. En el caso bayesiano , sin embargo, además de la muestra también juega un papel fundamental la información previa o externa que se posee en relación a los fenómenos que se tratan de modelar. La estadística bayesiana está demostrando su utilidad en ciertas estimaciones basadas en el conocimiento subjetivo a priori y el hecho de permitir revisar esas estimaciones en función de la evidencia empírica es lo que está abriendo nuevas formas de hacer conocimiento. Una aplicación de esto son los clasificadores bayesianos que son frecuentemente usados en implementaciones de filtros de correo basura, que se adaptan con el uso. La estadística bayesiana es un tema muy interesante que merece un artículo en sí mismo. Para entender más fácilmente como funciona la estadística bayesiana veamos un simple ejemplo del lanzamiento de una moneda. La idea principal de la inferencia bayesiana es que la noción de probabilidad cambia mientras más datos tengamos. In [38]: sns . set_context ( rc = { \"figure.figsize\" : ( 11 , 9 )}) dist = stats . beta n_trials = [ 0 , 1 , 2 , 3 , 4 , 5 , 8 , 15 , 50 , 500 ] data = stats . bernoulli . rvs ( 0.5 , size = n_trials [ - 1 ]) x = np . linspace ( 0 , 1 , 100 ) for k , N in enumerate ( n_trials ): sx = plt . subplot ( len ( n_trials ) / 2 , 2 , k + 1 ) plt . xlabel ( \"$p$, probabilidad de cara\" ) \\ if k in [ 0 , len ( n_trials ) - 1 ] else None plt . setp ( sx . get_yticklabels (), visible = False ) heads = data [: N ] . sum () y = dist . pdf ( x , 1 + heads , 1 + N - heads ) plt . plot ( x , y , label = \"lanzamientos observados %d , \\n %d caras\" % ( N , heads )) plt . fill_between ( x , 0 , y , color = \"#348ABD\" , alpha = 0.4 ) plt . vlines ( 0.5 , 0 , 4 , color = \"k\" , linestyles = \"--\" , lw = 1 ) leg = plt . legend () leg . get_frame () . set_alpha ( 0.4 ) plt . autoscale ( tight = True ) plt . suptitle ( \"Actualizacion Bayesiana de probabilidades posterios\" , y = 1.02 , fontsize = 14 ) plt . tight_layout () Como el gráfico de arriba muestra, cuando empezamos a observar nuevos datos nuestras probabilidades posteriores comienzan a cambiar y moverse. Eventualmente, a medida que observamos más y más datos (lanzamientos de monedas), nuestras probabilidades se acercan más y más hacia el verdadero valor de p = 0.5 (marcado por una línea discontinua). Aquí termina este tutorial, espero que les haya sido util. Saludos! Este post fue escrito utilizando IPython notebook. Pueden descargar este notebook o ver su version estática en nbviewer .","tags":"Pobabilidad y Estadistica","url":"/blog/2018/10/22/probabilidad-y-estadistica-con-python/"},{"title":"Introducción al Cálculo con Python","text":"Introducción El Cálculo es una rama muy importante de la Matemática moderna; tiene profundas raíces en problemas físicos y gran parte de su potencia y belleza derivan de la variedad de sus aplicaciones. Las subramas conocidas como Cálculo integral y Cálculo diferencial son instrumentos naturales y poderosos para atacar múltiples problemas que surgen en Física , Astronomía , Ingeniería , Química , Geología , Biología , y en otros campos de las ciencias. El Cálculo no sólo es un instrumento técnico, sino que contiene una colección de ideas fascinantes y atrayentes que han ocupado el pensamiento humano durante cientos de años. Estas ideas están relacionadas con la velocidad, el área, el volumen, la razón de crecimiento, la tangente a una línea, y demás. Historia El origen del Cálculo se remonta a más de 2300 años, cuando los griegos intentaban resolver el problema del área ideando el procedimiento que llamaron método de exhaución . La idea esencial de este método consiste en intentar determinar el área de una región por medio de aproximaciones utilizando regiones poligonales cuya área sea más fácil de calcular, la idea es continuar con el proceso aumentando los lados de los polígonos hasta llegar a la mejor aproximación posible de la región que queremos determinar. Este método fue usado satisfactoriamente por Arquímedes (287-212 A.C.) para hallar fórmulas exactas de las áreas del círculo y de algunas otras figuras especiales. En la siguiente figura podemos ver al método de exhaución aplicado para determinar el área del círculo . Desde Arquímedes , gradualmente, el método de exhaución fue transformándose en lo que hoy se conoce como Cálculo integral , nueva y potente disciplina que, como ya mencionamos, tiene numerosas aplicaciones no sólo en problemas relativos a áreas y volúmenes, sino también en problemas de otras ciencias. El Cálculo integral , que mantiene alguno de los caracteres originales del método de exhaución , recibió su mayor impulso en el siglo XVII, debido a los esfuerzos de Isaac Newton (1642-1727) y Gottfried Leibniz (1646-1716), y su desarrollo continuó durante el siglo XIX, hasta que Augustin-Louis Cauchy (1789-1857) y Bernhard Riemann (1826-1866) le dieron una base matemática firme. Funciones Las Funciones son los objetos fundamentales con los que tratamos en el Cálculo . Las mismas pueden ser representadas de diferentes maneras: por una ecuación , en una tabla, por un gráfico, o en palabras. Se utilizan principalmente como modelos matemáticos para representar fenómenos del mundo real. La palabra Función fue introducida en las Matemáticas por Leibniz , quien utilizaba este término para designar cierto tipo de fórmulas matemáticas. Una Función surge cada vez que una cantidad depende de otra. Más precisamente la definición de Función es esencialmente la siguiente: Dados dos conjuntos de objetos, el conjunto X y el conjunto Y, una Función es una regla que asocia a cada objeto de X, uno y sólo un, objeto en Y. El conjunto X se denomina el dominio de la Función . Los objetos de Y, asociados con los objetos en X forman otro conjunto denominado el recorrido de la Función . Generalmente se utilizan las letras $f, g, h, G$ y $H$ para designarlas. Si $f$ es una función dada y $x$ es un objeto de su dominio, la notación $f(x)$ se utiliza para designar el objeto que en el recorrido corresponde a $x$, en la Función $f$, y se denomina el valor de la función $f$ en $x$. El símbolo $f(x)$ se lee, «f de x». Muchas veces resulta útil pensar en una Función como si fuera una máquina. Si $x$ está en el dominio de la función $f$, entonces cuando $x$ entra en la máquina, se acepta como una entrada y la máquina produce una salida $f(x)$ de acuerdo a la regla de la función. Así, podemos pensar al dominio como el conjunto de todas las entradas posibles y al recorrido como el conjunto de todas las salidas posibles. El método más común para la visualización de una Función es su gráfica . Si $f$ es una Función con dominio $D$, a continuación, su gráfica es el conjunto de pares ordenados . $$\\{(x, f(x)) \\mid x \\in D \\} $$ Aquí debemos tener en cuenta que el par $(x, f(x))$, es un par entrada-salida , el valor de $x$ representa el valor de entrada, mientras que el valor de $f(x)$ representa la salida de la Función . En otras palabras, la gráfica de $f$ se compone de todos puntos $(x, y)$ en el plano de coordenadas tal que $y=f(x)$ y $x$ está en el dominio de $f$. La gráfica de una Función $f$ nos da una imagen útil del comportamiento o la \"historia de vida\" de la misma. Funciones con Python Para definir las Funciones en Python utilizamos la instrucción def . Así por ejemplo si quisiéramos definir a la Función $f(x) = \\sqrt{x + 2}$ dentro de Python , lo podríamos hacer de la siguiente forma: In [1]: import numpy as np def f ( x ): return np . sqrt ( x + 2 ) En este ejemplo, primero estamos importando la librería numpy , para trabajar más fácilmente con vectores , los cuales simplifican los cálculos numéricos. Luego utilizamos la instrucción def para definir la función, que este caso se va a llamar f y va a tener como único parámetro al objeto x. Esta función nos va a devolver el valor de la raíz cuadrada de $x + 2$. Ahora, si por ejemplo quisiéramos saber los valores de la función $f(x)$ para los $x, -2, -1, 0, 2, 4$ y $6$. podríamos invocar a esta función de la siguiente manera: In [2]: x = np . array ([ - 2 , - 1 , 0 , 2 , 4 , 6 ]) # Creando el vector de valores de x y = f ( x ) y Out[2]: array([ 0. , 1. , 1.41421356, 2. , 2.44948974, 2.82842712]) Si quisiéramos verlo en forma de tabla, podemos ayudarnos de la librería pandas y su estructura de datos DataFrame , la cual tiene una forma tabular. In [3]: import pandas as pd tabla = pd . DataFrame ( list ( zip ( x , y )), columns = [ 'x' , 'f(x)' ] ) tabla Out[3]: x f(x) 0 -2 0.000000 1 -1 1.000000 2 0 1.414214 3 2 2.000000 4 4 2.449490 5 6 2.828427 Por último, si quisiéramos graficar funciones con Python , podemos utilizar la librería Matplotlib , y pasarle los valores de $x$ e $y$ al método plot del objeto pyplot . In [4]: % matplotlib inline import matplotlib.pyplot as plt def move_spines (): \"\"\"Esta funcion divide pone al eje y en el valor 0 de x para dividir claramente los valores positivos y negativos.\"\"\" fix , ax = plt . subplots () for spine in [ \"left\" , \"bottom\" ]: ax . spines [ spine ] . set_position ( \"zero\" ) for spine in [ \"right\" , \"top\" ]: ax . spines [ spine ] . set_color ( \"none\" ) return ax x = np . linspace ( - 2 , 6 , num = 30 ) ax = move_spines () ax . grid () ax . plot ( x , f ( x )) plt . title ( r \"Grafico de $f(x)=\\sqrt{x + 2}$\" ) plt . ylabel ( 'f(x)' ) plt . xlabel ( 'x' ) plt . show () Límites Uno de los conceptos más importantes dentro del Cálculo es el concepto de Límite . Se dice que una función $f$ tiende hacia el Límite $l$ cerca de $a$, si se puede hacer que $f(x)$ este tan próxima como queramos de $l$, haciendo que $x$ esté suficientemente cerca de $a$, pero siendo distinta de $a$. Así por ejemplo si analizamos la función $f(x) = x&#94;2 - x + 2$, para los valores cercanos a 2, podríamos ver los siguientes resultados. In [5]: # <!-- collapse=True --> def f ( x ): return x ** 2 - x + 2 x = np . array ([ 1 , 1.5 , 1.9 , 1.95 , 1.99 , 1.999 , 2.001 , 2.05 , 2.1 , 2.2 , 2.5 , 3 ]) y = f ( x ) tabla = pd . DataFrame ( list ( zip ( x , y )), columns = [ 'x' , 'f(x)' ]) tabla Out[5]: x f(x) 0 1.000 2.000000 1 1.500 2.750000 2 1.900 3.710000 3 1.950 3.852500 4 1.990 3.970100 5 1.999 3.997001 6 2.001 4.003001 7 2.050 4.152500 8 2.100 4.310000 9 2.200 4.640000 10 2.500 5.750000 11 3.000 8.000000 de acuerdo con esta tabla, podemos ver que a medida que hacemos al valor de $x$ cercano a 2, vemos que $f(x)$ se hace muy cercana a 4. Incluso podríamos hacer a $f(x)$ tan cercana como queramos a 4, haciendo que $x$ este lo suficientemente cerca de 2. Por lo tanto, podemos expresar esta propiedad diciendo que el \" Límite de la función $f(x) = x&#94;2 - x + 2$ cuando $x$ se acerca a 2 es igual a 4.\" y lo podemos representar con la siguiente notación: $$\\lim_{x\\to 2} \\left(x&#94;2 -x + 2\\right) = 4$$ Gráficamente lo podemos ver del siguiente modo. In [6]: # <!-- collapse=True --> x = np . linspace ( - 2 , 4 , num = 30 ) ax = move_spines () ax . grid () ax . plot ( x , f ( x )) ax . scatter ( 2 , 4 , label = \"limite cuando x tiende a 2\" , color = 'r' ) plt . legend () plt . title ( r \"Grafico de $f(x)=x&#94;2 -x + 2$\" ) plt . ylabel ( 'f(x)' ) plt . xlabel ( 'x' ) plt . show () Las leyes de los límites Calcular el valor exacto de los Límites muchas veces no suele tan fácil como reemplazar el valor de $a$ en $f(x)$. Es por esto que es importante conocer algunas propiedades de los Límites , ellas son: Ley de la suma: El límite de la suma de dos funciones es la suma de sus límites. Ley de la diferencia: El límite de la diferencia de dos funciones es la diferencia de sus límites. Ley del producto: El límite del producto de dos funciones es el producto de sus límites. ley del múltiplo constante: El límite de una constante por una función es la constante por el límite de la función. Ley del cociente: El límite del cociente de dos funciones es el cociente de sus límites, siempre que el límite del denominador sea diferente de cero . Es decir que si tenemos a la constante $C$ y a los límites $\\lim_{x\\to a} f(x)$ y $\\lim_{x\\to a} g(x)$. Entonces podemos expresar estas propiedades matemáticamente de la siguiente forma: 1- Ley de la suma: $\\lim_{x\\to a} [f(x) + g(x)] = \\lim_{x\\to a} f(x) + \\lim_{x\\to a} g(x)$. 2- Ley de la diferencia: $\\lim_{x\\to a} [f(x) - g(x)] = \\lim_{x\\to a} f(x) - \\lim_{x\\to a} g(x)$. 3- Ley del producto: $\\lim_{x\\to a} [f(x) \\cdot g(x)] = \\lim_{x\\to a} f(x) \\cdot \\lim_{x\\to a} g(x)$. 4- ley del multiplo constante: $\\lim_{x\\to a} [C \\cdot f(x)] = C \\cdot \\lim_{x\\to a} f(x)$. 5- Ley del cociente: $\\lim_{x\\to a} \\left[\\frac{f(x)}{g(x)}\\right] = \\frac{\\lim_{x\\to a} f(x)}{\\lim_{x\\to a} g(x)}$, si $\\lim_{x\\to a} g(x) \\ne 0$. Calculando Límites con Python Con Python , podemos resolver Límites fácilmente utilizando la librería SymPy , la cual nos proporciona el objeto Limit para representarlos en Python . Su sintaxis es la siguiente: Limit(función, variable, punto) . Entonces para calcular el límite de $f(x)$ cuando $x$ tiende a 0, debemos escribir: Limit(f(x), x, 0) Lo utilizamos de la siguiente forma: In [7]: from sympy.interactive import printing from sympy import Limit , limit , Symbol , S # imprimir con notación matemática. printing . init_printing ( use_latex = 'mathjax' ) x = Symbol ( 'x' ) # Creando el simbolo x. Limit ( x ** 2 - x + 2 , x , 2 ) # Creando el objeto Limit Out[7]: $$\\lim_{x \\to 2&#94;+}\\left(x&#94;{2} - x + 2\\right)$$ In [8]: # Resolviendo el Limite con el metodo doit() Limit ( x ** 2 - x + 2 , x , 2 ) . doit () Out[8]: $$4$$ In [9]: # La funcion limit nos da directamente el resultado limit ( x ** 2 - x + 2 , x , 2 ) Out[9]: $$4$$ In [10]: # Resolviendo limite 1/x cuando x tiende a infinito Limit ( 1 / x , x , S . Infinity ) Out[10]: $$\\lim_{x \\to \\infty} \\frac{1}{x}$$ In [11]: Limit ( 1 / x , x , S . Infinity ) . doit () Out[11]: $$0$$ Como vemos, primero creamos el símbolo para representar a la variable x utilizando el objeto Symbol , y luego creamos nuestro límite utilizando el objeto Limit . Por último para resolver el límite, simplemente llamamos al método doit() sobre el objeto Limit que acabamos de crear. También podemos calcular los Límites de valores de $x$ que tiendan hacia el infinito utilizando la clase especial S.Infinity que nos proporciona SymPy . Ahora que ya conocemos que es una Función y que es un Límite , ya estamos en condiciones de adentrarnos en el Cálculo diferencial y analizar el concepto de Derivada . Derivadas Para poder comprender el concepto de Derivada primero debemos abordar el problema de la recta tangente a un curva. La palabra tangente se deriva de la palabra griega Tangens , que significa \"que toca\". Así una tangente a una curva es una línea que toca la curva. En otras palabras, una línea tangente debe tener la misma dirección que la curva en el punto de contacto. Para un círculo podríamos simplemente seguir la definición de Euclides y decir que la tangente es una línea que cruza el círculo una y sólo una vez (ver figura a ). Pero para curvas más complicadas este definición es inadecuada. Por ejemplo en la figura b podemos ver dos líneas $l$ y $t$ que pasan por el punto $P$ en una curva $C$ . La línea $l$ cruza a la curva $C$ sólo una vez, pero ciertamente no se parece a lo que pensamos como una tangente . La línea $t$, en cambio, se parece a una tangente pero intercepta a $C$ dos veces. El intento de resolver este problema fue lo que condujo a Fermat a descubrir algunas de las ideas rudimentarias referentes a la noción de Derivada . Aunque la derivada se introdujo inicialmente para el estudio del problema de la tangente, pronto se vio que proporcionaba también un instrumento para el cálculo de velocidades y, en general para el estudio de la variación o tasa de cambio de una función. La Derivada de una función es una medida de la rapidez con la que cambia el valor de dicha función, según cambie el valor de su variable independiente . La Derivada de una función es un concepto local, es decir, se calcula como el límite de la rapidez de cambio medio de la función en un cierto intervalo, cuando el intervalo considerado para la variable independiente se torna cada vez más pequeño. Por ello se habla del valor de la derivada de una cierta función en un punto dado. Entonces el valor de la Derivada de una función en un punto puede interpretarse geométricamente, ya que se corresponde con la pendiente de la recta tangente a la gráfica de la función en dicho punto. La recta tangente es a su vez la gráfica de la mejor aproximación lineal de la función alrededor de dicho punto. La noción de Derivada puede generalizarse para el caso de funciones de más de una variable con la derivada parcial y el diferencial . Matemáticamente, la Derivada es una caso especial de Límite , el cual surge cada vez que queremos calcular la pendiente de la recta tangente o la velocidad de cambio de un objeto. Éste Límite ocurre tan frecuentemente que se le ha da un notación y un nombre determinados. Así la Derivada de una función $f$ en el punto a , representada por $f'(a)$, es: $$f'(a) = \\lim_{h \\to 0}\\frac{f(a + h) - f(a)}{h}$$ donde $h$ representa la variación de $a$. Esta misma definición, puede ser representada también del siguiente modo, utilizando la notación de Leibniz . $$\\frac{dy}{dx} = \\lim_{dx \\to 0}\\frac{f(x + dx) - f(x)}{dx}$$ Así, por ejemplo si quisiéramos saber cuál es la Derivada de la función $f(x) = x&#94;3$, podemos aplicar la definición anterior del siguiente modo. Comenzamos, definiendo a $f(x + dx) = (x + dx)&#94;3$, luego expandimos a: $$(x + dx)&#94;3 = f(x + dx) = x&#94;3 + 3x&#94;2dx + 3xdx&#94;2 + dx&#94;3$$ Luego reemplazamos esta función en nuestra definición de Derivada : $$\\frac{dx}{dy} = \\frac{x&#94;3 + 3x&#94;2dx + 3xdx&#94;2 + dx&#94;3 - x&#94;3}{dx}$$ Simplificamos los términos: $$\\frac{dx}{dy} = \\frac{3x&#94;2dx + 3xdx&#94;2 + dx&#94;3}{dx} \\Rightarrow 3x&#94;2 + 3xdx + dx&#94;2$$ y cuando $dx$ tiende a cero, obtenemos finalmente la función Derivada : $$\\frac{d}{dx}x&#94;3 = 3x&#94;2$$ Reglas de Derivación Si fuera siempre necesario calcular las Derivadas directamente de la definición, como hicimos anteriormente, éstos cálculos podrían ser tediosos y complicados. Afortunadamente, varias reglas se han desarrollado para encontrar Derivadas sin tener que usar la definición directamente. Estas fórmulas simplifican enormemente la tarea de la diferenciación y se conocen como reglas de derivación . Algunas de ellas son las siguientes: Funciones comunes Función original Función Derivada Constantes $c$ 0 $x$ 1 Cuadrado $x&#94;2$ $2x$ Raiz cuadrada $\\sqrt{x}$ $\\frac{1}{2}x&#94;{-\\frac{1}{2}}$ Exponenciales $e&#94;x$ $e&#94;x$ $a&#94;x$ $a&#94;x(\\ln a)$ Logaritmicas $\\ln x$ $\\frac{1}{x}$ $\\log_{a} x$ $\\frac{1}{x \\ln a}$ Trigonométricas $\\sin x$ $\\cos x$ $\\cos x$ $-\\sin x$ $\\tan x$ $\\sec&#94;2(x)$ Trigonométricas inversas $\\sin&#94;{-1}(x)$ $\\frac{1}{\\sqrt{1-x&#94;2}}$ $\\cos&#94;{-1}(x)$ $\\frac{-1}{\\sqrt{1-x&#94;2}}$ $\\tan&#94;{-1}(x)$ $\\frac{1}{1-x&#94;2}$ 1- Regla de la función de grado n: Esta regla nos dice que una función de grado n, donde n es un exponente real, se representa por $f(x)=x&#94;{n}$ y su derivada es $f'(x)=nx&#94;{n-1}$. Así por ejemplo, si quisiéramos saber la derivada de $f(x) = x&#94;5$, aplicando la regla obtenemos, $f'(x) = 5x&#94;{5-1} \\Rightarrow 5x&#94;4$. 2- Regla de la multiplicación por una constante: Esta regla establece que una función con la forma $f(x) = Cx$, donde $C$ es una constante; entonces la derivada de esta función va a ser igual a: $f'(x)= Cx'$; es decir a la constante por la derivada de $x$. Así por ejemplo si tenemos la función $f(x)=5x&#94;3$, primero debemos a obtener la derivada de $x&#94;3$, la cual aplicando la regla anterior sabemos que es $3x&#94;2$ y luego a esta derivada la multiplicamos por la constante 5, para obtener el resultado final $f'(x)=15x&#94;2$. 3- Regla de la suma: Esta regla establece que la derivada de la suma de dos funciones es igual a la suma de las derivadas de cada una de ellas. Es decir, $(f+g)'(x)=f'(x)+g'(x)$. Así por ejemplo la derivada de la función $f(x) = 5x&#94;3 + x&#94;2$ va a ser igual a $f'(x) = 15x&#94;2 + 2x$. 4- Regla de la diferencia: Esta regla establece que la derivada de la diferencia entre dos funciones es igual a la diferencia entre las derivadas de cada una de ellas. Es decir, $(f-g)'(x)=f'(x)-g'(x)$. Así por ejemplo la derivada de la función $f(x) = 5x&#94;3 - x&#94;2$ va a ser igual a $f'(x) = 15x&#94;2 - 2x$. 5- Regla del producto: Esta regla establece que la derivada de un producto de dos funciones es equivalente a la suma entre el producto de la primera función sin derivar y la derivada de la segunda función y el producto de la derivada de la primera función por la segunda función sin derivar. Es decir, $(f\\cdot g)' = f'\\cdot g + f\\cdot g'$. Así por ejemplo si quisiéramos derivar la función $h(x)=(2x + 1)(x&#94;3 + 2)$, primero obtenemos las derivadas de cada termino, $f'(x)=2$ y $g'(x)=3x&#94;2$ y luego aplicamos la formula $h'(x)=2(x&#94;3 +2) + (2x + 1)3x&#94;2$, los que nos da un resultado final de $h'(x)=8x&#94;3 + 3x&#94;2 + 4$. 6- Regla del cociente: Esta regla establece que la derivada de un cociente de dos funciones es la función ubicada en el denominador por la derivada del numerador menos la derivada de la función en el denominador por la función del numerador sin derivar, todo sobre la función del denominador al cuadrado. Es decir, $\\left(\\frac{f}{g}\\right)'=\\frac{f'g-fg'}{g&#94;{2}}$. Por ejemplo, para obtener la derivada de la función $h(x) = \\frac{3x + 1}{2x}$, aplicando la formula obtenemos que $h'(x) = \\frac{3 \\cdot (2x) - (3x + 1) \\cdot 2}{2x&#94;2}$, y simplificando llegamos al resultado final de $h'(x) = -\\frac{1}{2x&#94;2}$. 7- Regla de la cadena: La regla de la cadena es una fórmula para calcular la derivada de la composición de dos o más funciones. Esto es, si $f$ y $g$ son dos funciones, entonces la regla de la cadena expresa la derivada de la función compuesta $f(g(x))$ en términos de las derivadas de $f$ y $g$. Esta derivada va a ser calculada de acuerdo a la siguiente formula: $f'(g(x)) = f'(g(x)) \\cdot g'(x)$. Por ejemplo, si quisiéramos saber la derivada de la función $h(x) = \\sin(x&#94;2)$, aplicando la formula obtenemos que $h'(x) = \\cos(g(x)) \\cdot 2x$, lo que es igual a $h'(x) = 2x \\cos(x&#94;2)$. Derivadas de mayor orden Si tenemos una función $f$, de la cual podemos obtener su derivada $f'$, la cual también es otra función que podemos derivar, entonces podemos obtener la derivada de segundo orden de $f$, la cual representaremos como $f''$. Es decir, que la derivada de segundo orden de $f$, va a ser igual a la derivada de su derivada. Siguiendo el mismo proceso, podemos seguir subiendo en la jerarquía y obtener por ejemplo, la tercer derivada de $f$. Utilizando la notación de Leibniz , expresaríamos a la segunda derivada del siguiente modo: $$\\frac{d}{dy}\\left(\\frac{dy}{dx}\\right)= \\frac{d&#94;2y}{dx&#94;2}$$ Calculando Derivadas con Python Con Python , podemos resolver Derivadas utilizando nuevamente la librería SymPy . En este caso, ahora vamos a utilizar el objeto Derivative . Su sintaxis es la siguiente: Derivative(funcion, variable, orden de derivación) . Lo utilizamos de la siguiente forma: In [12]: from sympy import Derivative , diff , simplify fx = ( 2 * x + 1 ) * ( x ** 3 + 2 ) dx = Derivative ( fx , x ) . doit () dx Out[12]: $$2 x&#94;{3} + 3 x&#94;{2} \\left(2 x + 1\\right) + 4$$ In [13]: # simplificando los resultados simplify ( dx ) Out[13]: $$8 x&#94;{3} + 3 x&#94;{2} + 4$$ In [14]: # Derivada de segundo orden con el 3er argumento. Derivative ( fx , x , 2 ) . doit () Out[14]: $$6 x \\left(4 x + 1\\right)$$ In [15]: # Calculando derivada de (3x +1) / (2x) fx = ( 3 * x + 1 ) / ( 2 * x ) dx = Derivative ( fx , x ) . doit () simplify ( dx ) Out[15]: $$- \\frac{1}{2 x&#94;{2}}$$ In [16]: # la función diff nos da directamente el resultado simplify ( diff ( fx , x )) Out[16]: $$- \\frac{1}{2 x&#94;{2}}$$ In [17]: # con el metodo subs sustituimos el valor de x # para obtener el resultado numérico. Ej x = 1. diff ( fx , x ) . subs ( x , 1 ) Out[17]: $$- \\frac{1}{2}$$ Como podemos ver, el método para calcular las Derivadas con Python , es muy similar al que vimos anteriormente al calcular los Límites . En el ejemplo, también utilizamos la función simplify , la cual nos ayuda a simplificar los resultados; y el método subs para sustituir el valor de $x$ y obtener el resultado numérico. Ahora que ya conocemos al Cálculo diferencial , es tiempo de pasar hacia la otra rama del Cálculo , el Cálculo integral , y analizar el concepto de Integración . Integrales La idea de Integral es el concepto básico del Cálculo integral . Pero para poder comprender este concepto, primero debemos abordar el problema del área . Como bien sabemos, el área es una medida de la extensión de una superficie. Determinar esta medida para superficies con líneas rectas , suele ser bastante fácil. Por ejemplo para un rectángulo, su área se define como el producto de la longitud y el ancho. O para un triángulo como la mitad de la base por la altura. El área de cualquier otro polígono se encuentra al dividirlo en triángulos y luego sumar las áreas de cada uno ellos. Pero para los casos de las regiones con líneas curvas , el cálculo del área ya no suele ser tan fácil. Para estos casos debemos recurrir a un método similar al de exhaución que mencionábamos en la introducción del artículo. Es decir, que vamos a ir dividiendo la región en varios rectángulos de $\\Delta x$ de ancho y luego podemos ir calculando el área como la suma del las áreas de cada uno de estos rectángulos. A medida que vamos agregando más rectángulos, haciendo $\\Delta x$ cada vez más pequeño, nos vamos aproximando cada vez más al valor real del área de la superficie curva. Hasta el punto de que, cuando $\\Delta x$ tiende a cero, podemos alcanzar el resultado exacto del área de nuestra superficie curva. Es decir, que realizando una suma de infinitamente más angostos rectángulos, podemos determinar el resultado exacto del área de nuestra superficie curva. Este proceso lo podemos ver más claramente en la siguiente figura. Como vemos, al igual que pasaba con el caso de las Derivadas , al querer calcular el área de una superficie curva, nos encontramos ante un caso especial de Límite (aquí vemos también por qué el concepto de Límite es tan importante para el Cálculo !). Este tipo de Límite surge en una amplia variedad de situaciones, no solo al calcular áreas , sino que también lo podemos encontrar al calcular la distancia recorrida por un objeto o el volumen de un sólido. Por lo tanto, se le ha dado una notación y un nombre determinado. De esta forma la definición matemática de la Integral definida, sería la siguiente: Si $f$ es una función definida por $a \\leqslant x \\leqslant b$, podemos dividir el intervalo $[a, b]$ en $n$ subintervalos de $\\Delta x(b - a) / n$ de ancho. Dónde $x_0(=a), x_1, x_2, \\dots, x_n(=b)$ serán los puntos finales de estos subintervalos y $x_1&#94;*, x_2&#94;*, \\dots, x_n&#94;*$, serán puntos intermedios en estos subintervalos, de tal forma que $x_i&#94;*$ se encuentre en el k-simo subintervalo $[x_{i-1}, x_i]$. Entonces la Integral definida de $f$ entre $a$ y $b$, es: $$\\int_a&#94;b f(x) dx = \\lim_{n \\to \\infty}\\sum_{i=1}&#94;n f(x_i&#94;*) \\Delta x $$ El símbolo de la Integral , $\\int$, fue introducido por Leibniz , viene a ser una \"S\" alargada y fue elegido ya que la Integral es en definitiva un Límite de sumas infinitesimales . En esta notación, $a$ y $b$ son los límites de la integración y $dx$ indica que $x$ es la variable independiente. La suma: $$\\sum_{i=1}&#94;n f(x_i&#94;*) \\Delta x $$ que vemos en la definición, es conocida como la suma de Reimann , en honor al matemático alemán Bernhard Reimann que la desarrolló. Integrales definidas e indefinidas Una distinción importante que debemos hacer al hablar de Integrales , es la diferencia entre una Integral definida y una integral indefinida o antiderivada . Mientras que la Integral definida , que representamos con el símbolo, $\\int_a&#94;b f(x) dx$, es un número , un resultado preciso de la medida de un área , distancia o volumen; la integral indefinida , que representamos como, $\\int f(x) dx$, es una función o familia de funciones. Más adelante, cuando hablemos del teorema fundamental del cálculo , veremos por qué esta distinción es tan importante. Pero antes, veamos como podemos hacer para calcular Integrales . Reglas de integración Cómo podemos ver de la definición que dimos de Integrales , estas parecen sumamente complicadas de calcular. Por suerte, al igual que para el caso de Derivadas , existen varias reglas que podemos utilizar para poder calcular las integrales indefinidas , en forma más sencilla. Algunas de ellas son: Funciones comunes Función original Integral indefinida ($C$ es una constante) Constante $\\int a \\ dx$ $ax + C$ Variable $\\int x \\ dx$ $\\frac{x&#94;2}{2} + C$ Cuadrado $\\int x&#94;2 \\ dx$ $\\frac{x&#94;3}{3} + C$ Reciproca $\\int \\left(\\frac{1}{x}\\right) \\ dx$ $\\ln |x| + C $ Exponenciales $\\int e&#94;x \\ dx $ $e&#94;x + C$ $\\int a&#94;x \\ dx$ $\\frac{a&#94;x}{\\ln (a)} + C$ $\\int \\ln (x) \\ dx$ $x \\ \\ln(x) - x + C$ Trigonométricas $\\int \\sin (x) \\ dx$ $- \\cos (x) + C$ $\\int \\cos (x) \\ dx$ $\\sin (x) + C$ $\\int \\sec&#94;2(x) \\ dx$ $\\tan(x) + C$ 1- Regla de la función de grado n: Esta regla nos dice que una función de grado n, donde n es un exponente real distinto de -1, se representa por $f(x)=x&#94;{n}$ y su integral es $\\int x&#94;{n} \\ dx = \\frac{x&#94;{n + 1}}{n + 1} + C$. Así por ejemplo, si quisiéramos saber la integral de $f(x) = x&#94;3$, aplicando la regla obtenemos, $\\int x&#94;3 \\ dx = \\frac{x&#94;4}{4} + C$. 2- Regla de la multiplicación por una constante: Esta regla establece que una función con la forma $f(x) = Cx$, donde $C$ es una constante; entonces la integral de esta función va a ser igual a: $\\int Cx \\ dx = C\\int x \\ dx$; es decir a la constante por la integral de $x$. Así por ejemplo si tenemos la función $f(x)=4x&#94;3$, primero debemos a obtener la integral de $x&#94;3$, la cual aplicando la regla anterior sabemos que es $\\int x&#94;3 \\ dx = \\frac{x&#94;4}{4} + C $ y luego a esta integral la multiplicamos por la constante 4, para obtener el resultado final $\\int 4 x&#94;3 \\ dx = x&#94;4 + C$. 3- Regla de la suma: Esta regla establece que la integral de la suma de dos funciones es igual a la suma de las integrales de cada una de ellas. Es decir, $\\int (f + g) \\ dx = \\int f \\ dx + \\int g \\ dx$. Así por ejemplo la integral de la función $f(x) = 4x&#94;3 + x&#94;2$ va a ser igual a $\\int (4x&#94;3 + x&#94;2) \\ dx = x&#94;4 + \\frac{x&#94;3}{3} + C$. 4- Regla de la diferencia: Esta regla establece que la integral de la diferencia entre dos funciones es igual a la diferencia entre las integrales de cada una de ellas. Es decir, $\\int (f - g) \\ dx = \\int f \\ dx - \\int g \\ dx$. Así por ejemplo la integral de la función $f(x) = 4x&#94;3 - x&#94;2$ va a ser igual a $\\int (4x&#94;3 - x&#94;2) \\ dx = x&#94;4 - \\frac{x&#94;3}{3} + C$. En todos estos ejemplos, podemos ver la aparición de una misteriosa constante $C$, esta es la que se conoce como constante de integración . Esta constante expresa una ambigüedad inherente a la construcción de las integrales. Es por esta ambigüedad que cuando hablamos de la integral indefinida decimos que expresa una familia de funciones $f(x) + C$. Teorema fundamental del Cálculo El teorema fundamental del cálculo establece una conexión entre las dos ramas del Cálculo : el Cálculo diferencial y el Cálculo integral . Como ya hemos visto, el Cálculo diferencial surgió del problema de la tangente , mientras que el Cálculo integral surgió de un problema aparentemente sin relación con este, el problema del área . Fue Isaac Barrow , quien descubrió que estos dos problemas están en realidad estrechamente relacionados. De hecho, se dio cuenta de que la derivación y la integración son procesos inversos. El teorema fundamental del cálculo nos da la relación inversa precisa entre la Derivada y la Integral . Fueron Newton y Leibniz quienes aprovecharon esta relación y la utilizaron para desarrollar el Cálculo . En particular, vieron que esta relación les permitía calcular áreas e Integrales con mucha facilidad y sin tener que calcularlas como límites de sumas. Es decir, que si tomamos una función $f$, y obtenemos primero su Derivada , y luego calculamos la Integral sobre esta función Derivada $f'(x)$. Obtenemos nuevamente función original $f$. Lo que una hace, la otra lo deshace. El teorema fundamental del cálculo es sin duda el teorema más importante en el Cálculo y, de hecho, se ubica como uno de los grandes logros de la mente humana. Matemáticamente, este teorema se suele dividir en dos partes y nos dice lo siguiente: Teorema fundamental del Calculo, parte 1. si $f$ es una función continua en el intervalo $[a, b]$, entonces la función $g$ definida como: $$g(x) = \\int_a&#94;x f(t) dt \\qquad a \\leqslant x \\leqslant b $$ es continua en el intervalo $[a, b]$ y diferenciable en $(a, b)$, y $g'(x) = f(x)$. Teorema fundamental del Calculo, parte 2. si $f$ es una función continua en el intervalo $[a, b]$, entonces: $$\\int_a&#94;b f(x) dx = F(b) - F(a) $$ en donde $F$ es la antiderivada de $f$, o sea, una función tal que F' = f. En definitiva, lo que nos dice la primera parte es que las operaciones de derivación y de integración son operaciones inversas. La segunda parte nos proporciona un método para calcular integrales definidas , en base a la antiderivada o integral indefinida . Así, por ejemplo, si quisiéramos calcular la Integral : $$\\int_0&#94;3 (x&#94;3 - 6x) dx$$ primero obtenemos su integral indefinida . $$\\int (x&#94;3 - 6x) dx = \\frac{x&#94;4}{4} - 6\\frac{x&#94;2}{2}$$ y por último aplicamos la segunda parte del teorema fundamental del cálculo para obtener la integral definida en $[0, 3]$, reemplazando estos valores en la integral indefinida que acabamos de obtener. $$\\int_0&#94;3 (x&#94;3 - 6x) dx = \\left(\\frac{1}{4} \\cdot 3&#94;4 - 3 \\cdot 3&#94;2 \\right) - \\left(\\frac{1}{4} \\cdot 0&#94;4 - 3 \\cdot 0&#94;2 \\right) = -\\frac{27}{4}$$ Calculando Integrales con Python Con Python , podemos resolver Integrales con la ayuda de la, en este punto ya invaluable, librería SymPy . En este caso, vamos a utilizar el objeto Integral . Su sintaxis es la siguiente: Integral(funcion, variable) . Lo utilizamos de la siguiente forma: In [18]: from sympy import Integral , integrate fx = x ** 3 - 6 * x dx = Integral ( fx , x ) . doit () dx Out[18]: $$\\frac{x&#94;{4}}{4} - 3 x&#94;{2}$$ In [19]: # la función integrate nos da el mismo resultado integrate ( fx , x ) Out[19]: $$\\frac{x&#94;{4}}{4} - 3 x&#94;{2}$$ El objeto Integral también nos permite calcular integrales definidas . En este caso, en el segundo argumento le pasamos una tupla cuyo primer elemento es la variable de integración, su segundo elemento es el límite inferior de integración y el último es el límite superior. In [20]: # Calculando integral definida para [0, 3] Integral ( fx , ( x , 0 , 3 )) . doit () Out[20]: $$- \\frac{27}{4}$$ In [21]: # Comprobando Teorema fundamental del calculo. # Integración y diferenciacion son operaciones inversas. diff ( integrate ( fx )) Out[21]: $$x&#94;{3} - 6 x$$ In [22]: integrate ( diff ( fx )) Out[22]: $$x&#94;{3} - 6 x$$ Como podemos ver, el método para calcular las Integrales con Python , es muy similar a lo que ya veníamos utilizando al calcular Límites y Derivadas . Para calcular Integrales en forma numérica, también podemos recurrir al módulo scipy.integrate , el cual es muy útil para resolver ecuaciones diferenciales , pero eso ya va a quedar para otro artículo. Con esto concluyo esta introducción por el fascinante mundo del Cálculo , espero lo hayan disfrutado tanto como yo! Saludos! Este post fue escrito utilizando Jupyter notebook. Pueden descargar este notebook o ver su version estática en nbviewer .","tags":"Calculo","url":"/blog/2018/10/20/introduccion-al-calculo-con-python/"}]}